{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "from histolab.slide import Slide\n",
    "import csv\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, confusion_matrix, make_scorer, auc\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a590d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_data = wsi_dataset(file_path = 'train.txt',transform = data_transforms['train'])\n",
    "valid_data = wsi_dataset(file_path = 'valid.txt',transform = data_transforms['valid'])\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True) \n",
    "valid_dataloader = DataLoader(valid_data, batch_size=64, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d20db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model = resnet_model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update,lr=0.001)\n",
    "\n",
    "best_acc = 0\n",
    "epochs = 20\n",
    "acc_s = []\n",
    "loss_s = []\n",
    "for t in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f\"Epoch {t+1}\\n--------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    torch.save(model.state_dict(), \"stage1\\model_stage1_epochs_\"+str(t)+\"_train.pth\")\n",
    "    test(valid_dataloader, model, loss_fn)\n",
    "    torch.save(model.state_dict(), \"stage1\\model_stage1_epochs_\"+str(t)+\"_test.pth\")\n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time\n",
    "    print(\"time_diffï¼š\", time_diff)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f03e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(0, epochs), acc_s)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(0, epochs), loss_s)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show() \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6862c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "index_df = pd.read_csv(r'E:\\THT\\HE_DTC_txt\\index.csv')\n",
    "make_preds_by_slide_and_visualize(model_epoch_10, df_filtered, device, r\"E:\\THT\\HE_DTC_output\",visualize=True,out_all=False,\n",
    "                                  transform=data_transforms['valid'], batch_size=64, num_workers=0, n_classes=4, scale_factor=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4398e-579d-4375-b69c-025228f1004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model,params_to_update = model_initialization(dimension=3,freeze=False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = model_load(resnet_model,device,\"stage2_best_54\\model_stage2_epochs_\"+str(13)+\".pth\")\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(protein_valid_data, batch_size=64, shuffle=False)\n",
    "\n",
    "y_scores = []\n",
    "y_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)  \n",
    "        probs = torch.softmax(outputs, dim=1)  \n",
    "        y_scores.append(probs.cpu().numpy()) \n",
    "        y_labels.append(y_batch.cpu().numpy())\n",
    "y_probs = np.concatenate(y_scores)\n",
    "y_true = np.concatenate(y_labels)\n",
    "y_onehot_true = LabelBinarizer().fit(range(3)).transform(y_true)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = 3\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true == i, y_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652fbad-98f0-465d-959e-e908f54e6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_true, y_probs, multi_class='ovr',average='macro'))\n",
    "print(roc_auc_score(y_true, y_probs, multi_class='ovo',average='macro'))\n",
    "print(roc_auc_score(y_true, y_probs, multi_class='ovr',average='micro'))\n",
    "print(y_true.shape,y_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8b0be-a0e2-427b-b536-5f561cd77efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot_true = LabelBinarizer().fit(range(3)).transform(y_true)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_onehot_true.ravel(), y_probs.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    " \n",
    "# Compute macro-average ROC curve and ROC area\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    " \n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    " \n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    " \n",
    "# Plot all ROC curves\n",
    "lw=2\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    " \n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    " \n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    " \n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([-0.02, 1.0])\n",
    "plt.ylim([0.0, 1.02])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0309b9-6af7-4555-acc1-1a989fbf9c77",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_df_123 = pd.read_csv(r'E:\\THT\\HE_DTC_second\\second\\txt_123\\index.csv')\n",
    "resnet_model_epoch_10,params_no_use = model_initialization(4)\n",
    "model_epoch_10 = model_load(resnet_model_epoch_10,device,\"stage1\\model_stage1_epochs_10_train.pth\")\n",
    "model_epoch_10.eval()\n",
    "make_preds_by_slide_and_visualize(model_epoch_10, index_df_123, device, r\"E:\\THT\\HE_DTC_second\\second\\output\\model1_out\\123\",transform=data_transforms['valid'],\n",
    "                                  visualize=True,out_all=True,all_shuffle=False,batch_size=64, num_workers=0, n_classes=4, scale_factor=80,\n",
    "                                  wsi_type=\".mrxs\",sum_calc=True,pick_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320530a-f80a-4f6f-9416-171f8a26e526",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pick_index_df = pd.read_csv(r'E:\\THT\\HE_DTC_TCGA\\output\\model1_out\\txt\\pick_index.csv')\n",
    "output_dir = r'E:\\THT\\HE_DTC_TCGA\\output\\model2_2out'\n",
    "for t in range(21):\n",
    "    resnet_model,params_to_update = model_initialization(dimension=3,freeze=False)\n",
    "    model = model_load(resnet_model,device,\"stage2_best_54\\model_stage2_epochs_\"+str(t)+\".pth\")\n",
    "    model.eval()\n",
    "    make_preds_by_slide_and_visualize(model, pick_index_df, device, os.path.join(output_dir,str(t)), transform=data_transforms['valid'], \n",
    "                                      visualize=True,out_all=True,all_shuffle=False,batch_size=64, num_workers=0, n_classes=3, scale_factor=80,\n",
    "                                      wsi_type=\".svs\",sum_calc=True)\n",
    "    output_result = os.path.join(output_dir, str(t), 'output_result.csv')\n",
    "    data = []\n",
    "    pattern = re.compile(r\"(.+)_sum_out_label=(.+)\\.txt\")\n",
    "    for filename in os.listdir(os.path.join(output_dir,str(t))):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            wsi_name, out_label = match.groups()\n",
    "            data.append([wsi_name, out_label])\n",
    "    df = pd.DataFrame(data, columns=[\"wsi_name\", \"out_label\"])\n",
    "    df.to_csv(output_result, index=False)\n",
    "    print(f\"result: {output_result}\")\n",
    "    print(df['out_label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
